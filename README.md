
# My Project
## [LLM Inference Hardware Calculator](https://app.linpp2009.com/en/llm-gpu-memory-calculator)
Free LLM inference hardware calculator. Calculate GPU memory requirements, VRAM usage, and optimal hardware configuration for large language model deployment. Support for NVIDIA H100, A100, RTX series GPUs.

## [LLM Token Generation Speed Visualizer](https://app.linpp2009.com/en/token-generation-speed-visualizer)
Experience and understand how different token generation speeds affect user experience through this interactive visualization tool.

## [LLM Token Counter Visualizer](https://app.linpp2009.com/en/token-counter-visualizer)
Accurately count and visualize token breakdown for your text. Support GPT, Claude, DeepSeek and other model tokenizers with cost estimation and comparison features.
