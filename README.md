
# My Project
## [LLM Inference Hardware Calculator](https://app.linpp2009.com/en/llm-gpu-memory-calculator)
Free LLM inference hardware calculator. Calculate GPU memory requirements, VRAM usage, and optimal hardware configuration for large language model deployment. Support for NVIDIA H100, A100, RTX series GPUs.
![LLM Inference Hardware Calculator](https://github.com/user-attachments/assets/5103f1d4-3efa-4084-8c19-08805fc2538e)


## [LLM Token Generation Speed Visualizer](https://app.linpp2009.com/en/token-generation-speed-visualizer)
Experience and understand how different token generation speeds affect user experience through this interactive visualization tool.
![LLM Token Generation Speed Visualizer](https://github.com/user-attachments/assets/8c96f27c-9dbe-4e69-bbcd-f3f442bfc967)

## [LLM Token Counter Visualizer](https://app.linpp2009.com/en/token-counter-visualizer)
Accurately count and visualize token breakdown for your text. Support GPT, Claude, DeepSeek and other model tokenizers with cost estimation and comparison features.
![LLM Token Counter Visualizer](https://github.com/user-attachments/assets/38db7ce0-ca2e-4fae-a88f-fa14ed8fd785)
